game(19)
game(18)
game(17)
game(16)
x<-11:20
y<-rep(0,10)
for (i in 1:10){y[i]<-game(x[i])}
plot(x,y)
library(gpuR)
library(devtools)
install_github("cdeterman/gpuR")
library(httr)
resp<-GET(url="https://researchmap.jp/researchers?research_areas%5Bdiscipline_number%5D=A289&start=61")
x<-content(resp,type="text")
x
names(resp)
resp$content
class(resp$content)
?content
?GET
resp<-GET(url="https://researchmap.jp/researchers?research_areas%5Bdiscipline_number%5D=A289&start=61",add_headers(`User-Agent`="Mozilla/5.0 (compatible; R 4.1.0)"))
content(resp,"text")
ua<-"Mozilla/5.0 (Windows; U; Windows NT 5.1; ja; rv:1.8.1.20) Gecko/20081217 Firefox/2.0.0.20"
url<-"https://researchmap.jp/researchers?research_areas%5Bdiscipline_number%5D=A289&start=61"
?add_headers
add_headers
resp<-GET(url=url,add_headers(`User-Agent`=ua))
content(resp)
install.packages("rvest")
library(rvest)
x<-html(url)
??rvest
x<-read_html(url)
class(x)
x
length(x)
x[2]
x[[2]]
html_nodes(x)
html_nodes(x,"h1")
html_nodes(x,"h1") %>% html_text()
html_structure(x)
html_nodes(x,"li")
html_nodes(x,"div")
?html_nodes
?html_elements
?html_elements(x,"div")
html_elements(x,"div")
html_elements(x,"#list-inline")
html_elements(x,"#list-inline rm-cv-card")
html_elements(x,"#rm-cv-card")
html_elements(x,"li")
html_elements(x,"#rm-cv-card-outer")
html_elements(x,".rm-cv-card-outer")
card<-html_elements(x,".rm-cv-card-outer")
card[1]
html_element(card[1],".rm-cv-card-name")
html_element(card[1],".rm-cv-card-name") %>% html_text()
html_element(card[1],".rm-cv-card-affiliation") %>% html_text()
html_element(card[1],".rm-cv-card-name-affiliation") %>% html_text()
??trim
html_element(card[1],".rm-cv-card-name-affiliation") %>% html_text() %>% trimws()
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/scraper.R")
profs
view(profs)
profs[1]$name
profs$name[1]
x<-profs$name[1]
library(stringr)
substr(x,str_length(x),str_length(x))
Male_final1 <- c(
"夫", "雄", "男", "朗", "郎", "比古", "彦", "麻呂",
"麿", "満", "洋", "章", "顕", "嗣", "志", "八",
"鷹", "一", "助", "輔", "丞", "鉄", "哲", "道",
"通", "作", "兼", "鉄", "亮", "晃", "昭", "顕",
"士", "行", "則", "征", "浩", "宏", "博", "之",
"徳", "平", "兵", "介", "三", "五", "吾", "弘",
"寛", "憲", "煕", "伍", "迫", "暢", "隆", "崇",
"宗", "悟", "典", "馬", "武", "地", "人", "邦",
"匡", "斗", "翔", "勝", "将", "仁", "気", "機",
"謙", "久", "信", "延", "伸", "宣", "二", "広",
"巳", "吉", "収", "修", "児", "秀", "基", "?雅",
"至", "慶", "啓", "磨", "次", "康", "臣", "拓",
"輝", "彰", "俊", "峻", "駿", "祥", "視", "達",
"富", "高", "統", "騎", "城", "斉", "靖", "雍",
"泰", "真", "剛", "誉", "義", "範", "守", "拡",
"治", "敏", "久", "登", "賀", "忠", "就", "卓",
"斎", "多", "汰", "毅", "聞", "蔵", "充", "盈",
"允", "規", "正", "揮", "儀", "孝", "峰", "親",
"稔", "愉", "郷", "駄", "詞", "昌", "政", "旭",
"暉", "尊", "氏", "堂", "陛", "誠", "厚", "豪",
"進", "宝", "朝", "航", "國", "国", "頼", "経",
"氣")
if_male_final1 <- function(x) {
lastchr <- substr(x,str_length(x),str_length(x))
lastchr %in% Male_final1
}
if_male_final1(x)
x
if_male_final1(profs$name[2])
profs$name[2]
if_male_final1(profs$name[3])
if_male_final1(profs$name[4])
if_male_final1(profs$name[5])
profs$name[5]
?stringr
x<-'  "夫", "雄", "男", "朗", "郎", "比古", "彦", "麻呂",
"麿", "満", "洋", "章", "顕", "嗣", "志", "八",
"鷹", "一", "助", "輔", "丞", "鉄", "哲", "道",
"通", "作", "兼", "鉄", "亮", "晃", "昭", "顕",
"士", "行", "則", "征", "浩", "宏", "博", "之",
"徳", "平", "兵", "介", "三", "五", "吾", "弘",
"寛", "憲", "煕", "伍", "迫", "暢", "隆", "崇",
"宗", "悟", "典", "馬", "武", "地", "人", "邦",
"匡", "斗", "翔", "勝", "将", "仁", "気", "機",
"謙", "久", "信", "延", "伸", "宣", "二", "広",
"巳", "吉", "収", "修", "児", "秀", "基", "雅",
"至", "慶", "啓", "磨", "次", "康", "臣", "拓",
"輝", "彰", "俊", "峻", "駿", "祥", "視", "達",
"富", "高", "統", "騎", "城", "斉", "靖", "雍",
"泰", "真", "剛", "誉", "義", "範", "守", "拡",
"治", "敏", "久", "登", "賀", "忠", "就", "卓",
"斎", "多", "汰", "毅", "聞", "蔵", "充", "盈",
"允", "規", "正", "揮", "儀", "孝", "峰", "親",
"稔", "愉", "郷", "駄", "詞", "昌", "政", "旭",
"暉", "尊", "氏", "堂", "陛", "誠", "厚", "豪",
"進", "宝", "朝", "航", "國", "国", "頼", "経",
"氣"'
sub("[ ,]*","",x)
sub("[ ,\"]*","",x)
gsub("[ ,\"]*","",x)
library(rvest)
cont<-read_html("https://researchmap.jp/read0093842")
library(dplyr)
cont %>% html_elements(".rm-cv-research-interests") %>% html_text()
library(stringr)
cont %>% html_elements(".rm-cv-research-interests") %>% html_text()->x
x
str_split(x,"\\s+")
source("~/.active-rstudio-document")
get_keywords(cont)
get_keywords <- function(cont) {
x <- cont %>%
html_elements(".rm-cv-research-interests") %>%
html_text()
x <- str_split(x,"\\s+")[[1]]
x[x!=""]
}
get_keywords(cont)
get_elements(cont,"#published-papers")
html_elements(cont,"#published-papers")
html_elements(cont,".published-papers")
html_nodes(cont,"#published-papers")
html_nodes(cont,xpath="//*[@id="published_papers"]/span")
html_nodes(cont,xpath='//*[@id="published_papers"]/span')
html_nodes(cont,xpath='//*[@id="published_papers"]/span') %>% html_text()
get_no_papers <- function(cont) {
html_nodes(cont,xpath='//*[@id="published_papers"]/span') %>%
html_text() %>%
as.integer()
}
get_no_papers(cont)
1300*48
1300*30
1300*8
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
node$getNext(c("R","is"))
ww<-node$getNext(c("R","is"))
node$mlprob(c("R","is","not"))
node$mlprob(c("R","is","a"))
node$mlprob(c("R","is","that"))
node$getCount(c("R","is","that"))
node$getCount(c("R","is","a"))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
node$getCount(c("R","is","a"))
node$getCount(c("R","is","that"))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
node$mlprob(c("R","is","that"))
node$getCount(c("R","is","a"))
node$getNext(c("R","is"))
node$mlprob(c("R","is","that"))
node$mlprob(c("R","is","a"))
node$mlprob(c("R","is","not"))
node$mlprob(c("R","is","to"))
node$getCount(c("R","is","to"))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
node$getCount(c("R","is","to"))
node$mlprob(c("R","is","to"))
node$mlprob(c("R","is","the"))
node$mlprob(c("R","is","that"))
sum(sapply(node$vocab,function(w){node$mlprob(c("R","is",w))}))
sum(sapply(node$vocab,function(w){node$mlprob(c("R",w))}))
node$getNext("R")
sum(sapply(node$vocab,function(w){node$boprob(c("R",w))}))
sum(sapply(node$getNext("R")$word,function(w){node$boprob(c("R",w))}))
sum(sapply(node$vocab,function(w){node$boprob(c(w))}))
sum(sapply(node$getNext("R")$word,function(w){node$boprob(c("R",w))}))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sum(sapply(node$getNext("R")$word,function(w){node$boprob(c("R",w))}))
sum(sapply(node$vocab,function(w){node$boprob(c(w))}))
sum(sapply(node$vocab,function(w){node$boprob(c("R",w))}))
sum(sapply(node$vocab,function(w){node$boprob(c("R","is",w))}))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sapply(node$vocab,function(w){node$boprob(c("R","is",w))})
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sapply(node$vocab,function(w){node$boprob(c("R","is",w))})
sapply(node$vocab,function(w){node$mlprob(c("R","is",w))})
sapply(node$vocab,function(w){node$boprob(c("is",w))})
sapply(node$vocab,function(w){node$boprob(c("R",is",w))})
""
sapply(node$vocab,function(w){node$boprob(c("R","is",w))})
node$boprob(c("R","is","a"))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
node$boprob(c("R","is","a"))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
node$boprob(c("R","is","a"))
node$getAlpha(c("R","is"))
node$alpha
node$subnode[[2]]$alpha
node$subnode[[2]]
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
node$subnode[[2]]
sapply(node$vocab,function(w){node$boprob(c("R","is",w))})
sum(sapply(node$vocab,function(w){node$boprob(c("R","is",w))}))
node$boprob(c("R","is","a"))
0.4185*0.3333
0.4185714*0.3333
node$mlprob(c("R","is","a"))
node$getAlpha(c("R","is"))
node$getAlpha(c("R","is"))*node$mlprob(c("R","is","a"))
node$getAlpha(c("R","is"))*node$mlprob(c("R","is","a"))*3
sum(sapply(node$getNext(c("R","is"))$word,function(w){node$boprob(c("R","is",w))}))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sum(sapply(node$getNext(c("R","is"))$word,function(w){node$boprob(c("R","is",w))}))
sum(sapply(node$vocab,function(w){node$boprob(c("R","is",w))}))
0.7871049-0.4285714
sum(sapply(node$vocab,function(w){node$boprob(c("R",w))}))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sum(sapply(node$vocab,function(w){node$boprob(c("R",w))}))
sum(sapply(node$vocab,function(w){node$boprob(c("R","is",w))}))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sum(sapply(node$vocab,function(w){node$boprob(c("R",w))}))
sum(sapply(node$vocab,function(w){node$boprob(c("R","is",w))}))
sum(sapply(node$getNext("R","is")$word,function(w){node$boprob(c("R","is",w))}))
sum(sapply(node$getNext(c("R","is"))$word,function(w){node$boprob(c("R","is",w))}))
node$getAlpha(c("R","is"))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
node$getAlpha(c("R","is"))
sum(sapply(node$vocab,function(w){node$boprob(c("R","is",w))}))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sum(sapply(node$getNext(c("R","is"))$word,function(w){node$boprob(c("R","is",w))}))
library(dplyr)
node$getNext(c("R","is")
)
vocab<-data.frame(word=node$vocab)
vocab %>% dim()
vocab %>% filter(!(word %in% node$getNext(c("R","is"))$word)) %>% dim()
vocab %>% filter(!(word %in% node$getNext(c("R","is"))$word)) ->vocab2
sum(sapply(vocab2$word,function(w){node$boprob(c("R","is",w))}))
sum(sapply(node$getNext("R","is")$word,function(w){node$boprob(c("R","is",w))}))
sum(sapply(node$getNext(c("R","is"))$word,function(w){node$boprob(c("R","is",w))}))
1/0.3585335
1-0.4285714
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sum(sapply(node$vocab,function(w){node$boprob(c("R","is",w))}))
sum(sapply(vocab2$word,function(w){node$boprob(c("R","is",w))}))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sum(sapply(node$vocab,function(w){node$boprob(c("R","is",w))}))
sum(sapply(vocab2$word,function(w){node$boprob(c("R","is",w))}))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sum(sapply(vocab2$word,function(w){node$boprob(c("R","is",w))}))
sum(sapply(node$vocab,function(w){node$boprob(c("R","is",w))}))
sum(sapply(node$getNext(c("R","is"))$word,function(w){node$boprob(c("R","is",w))}))
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
sum(sapply(node$getNext(c("R","is"))$word,function(w){node$boprob(c("R","is",w))}))
sum(sapply(node$vocab,function(w){node$boprob(c("R","is",w))}))
sum(sapply(node$vocab,function(w){node$boprob(c("R",w))}))
sapply(node$vocab,function(w){node$boprob(c("R",w))})
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
source("G:/マイドライブ/MyDocument/東北大関係書類/2022/９人委員会/Researchmap/myngram.R")
ngram_lprob(ngram,tt)
ngram_lprob(ngram,tt[1:5])
ngram_lprob(ngram,tt[1:100])
ngram_lprob(ngram,tt[1:500])
length(tt)
ngram_lprob(ngram,tt[1:600])
ngram_lprob(ngram,tt[1:650])
ngram_lprob(ngram,tt[1:670])
ngram_lprob(ngram,tt[1:679])
ngram_lprob(ngram,tt[1:680])
tt[680]
tt <- str_split(tt,"\\s")[[1]]
ngram<-ngram_train(tt,"<s>","</s>")
ngram<-ngram_train(tt,3,"<s>","</s>")
ngram
ngram<-ngram_train(tt[1:500],3,"<s>","</s>")
ngram_lprob(tt[501:670])
traceback()
ngram_lprob(tt[501:503)
ngram_lprob(tt[501:503])
ngram_lprob(tt[501:503])
ngram_lprob(ngram,tt[501:503])
ngram_lprob(ngram,tt[501:670])
ngram_lprob(ngram,tt[1:200])
ngram_lprob(ngram,tt[1:3])
ngram_lprob(ngram,tt[1:4])
ngram_lprob(ngram,tt[1:5])
ngram$node$boprob(tt[1:3])
log(ngram$node$boprob(tt[1:3]))
log(ngram$node$boprob(tt[2:4]))
ngram$node$boprob(tt[2:4])
tt[2:4]
tt[1:3]
tt[1:10]
###
### test
tt <- "Computational text analysis has become an exciting research field with
many applications in communication research. It can be a difficult method
to apply, however, because it requires knowledge of various techniques,
and the software required to perform most of these techniques is not
readily available in common statistical software packages. In this teacher’s
corner, we address these barriers by providing an overview of general steps
and operations in a computational text analysis project, and demonstrate
how each step can be performed using the R statistical software. As a
popular open-source platform, R has an extensive user community that
develops and maintains a wide range of text analysis packages. We show
that these packages make it easy to perform advanced text analytics
With the increasing importance of computational text analysis in communication research
(Boumans & Trilling, 2016; Grimmer & Stewart, 2013), many researchers face the challenge of
learning how to use advanced software that enables this type of analysis. Currently, one of the most
popular environments for computational methods and the emerging field of “data science”
1 is the R
statistical software (R Core Team, 2017). However, for researchers that are not well-versed in
programming, learning how to use R can be a challenge, and performing text analysis in particular
can seem daunting. In this teacher’s corner, we show that performing text analysis in R is not as hard
as some might fear. We provide a step-by-step introduction into the use of common techniques, with
the aim of helping researchers get acquainted with computational text analysis in general, as well as
getting a start at performing advanced text analysis studies in R.
R is a free, open-source, cross-platform programming environment. In contrast to most programming languages, R was specifically designed for statistical analysis, which makes it highly suitable for
data science applications. Although the learning curve for programming with R can be steep,
especially for people without prior programming experience, the tools now available for carrying
out text analysis in R make it easy to perform powerful, cutting-edge text analytics using only a few
simple commands. One of the keys to R’s explosive growth (Fox & Leanage, 2016; TIOBE, 2017) has
been its densely populated collection of extension software libraries, known in R terminology as
packages, supplied and maintained by R’s extensive user community. Each package extends the
functionality of the base R language and core packages, and in addition to functions and data must
include documentation and examples, often in the form of vignettes demonstrating the use of the
package. The best-known package repository, the Comprehensive R Archive Network (CRAN),
currently has over 10,000 packages that are published, and which have gone through an extensive
screening for procedural conformity and cross-platform compatibility before being accepted by the
archive.2 R thus features a wide range of inter-compatible packages, maintained and continuously
updated by scholars, practitioners, and projects such as RStudio and rOpenSci. Furthermore, these
packages may be installed easily and safely from within the R environment using a single command.
R thus provides a solid bridge for developers and users of new analysis tools to meet, making it a
very suitable programming environment for scientific collaboration.
Text analysis in particular has become well established in R. There is a vast collection of dedicated
text processing and text analysis packages, from low-level string operations (Gagolewski, 2017) to
advanced text modeling techniques such as fitting Latent Dirichlet Allocation models (Blei, Ng, &
Jordan, 2003; Roberts et al., 2014) — nearly 50 packages in total at our last count. Furthermore, there
is an increasing effort among developers to cooperate and coordinate, such as the rOpenSci special
interest group.3 One of the main advantages of performing text analysis in R is that it is often
possible, and relatively easy, to switch between different packages or to combine them. Recent efforts
among the R text analysis developers’ community are designed to promote this interoperability to
maximize flexibility and choice among users.4 As a result, learning the basics for text analysis in R
provides access to a wide range of advanced text analysis features."
tt <- str_split(tt,"\\s")[[1]]
ngram<-ngram_train(tt[1:500],3,"<s>","</s>")
ngram_lprob(ngram,tt[501:670])
ngram_lprob(ngram,tt[501:503])
ngram_lprob(ngram,tt[501:510])
ngram_lprob(ngram,tt[501:504])
ngram_lprob(ngram,tt[502:504])
tt[502:504]
ngram$node$boprob(tt[502:504])
ngram$node$mlprob(tt[502:504])
ngram$node$mlprob(tt[503:504])
ngram$node$mlprob(tt[502:504])
ngram$node$mlprob(tt[502:503])
ngram$node$mlprob(tt[502:502])
ngram$node$getCount(tt[502:503])
ngram$node$getCount(tt[502])
library(devtools)
install_github("akinori-ito/RBackOffNgram")
library(RBackOffNgram)
x <- "The quick brown fox jumps over the lazy dog"
words <- strsplit(x," ")[[1]]
ngram <- ngram_train(words,3,unk_thres=0)
ngram_lprob(ngram,words)
install.packages("pkgsearch")
library(pkgsearch)
pkgsearch("gdbm")
??pkgsearch
pkg_search("gdbm")
pkg_search("dbm")
pkg_search("DBI",format="long")
source("G:/マイドライブ/MyDocument/研究室/内城/paper/VSMD/torchtest.R")
out
b[[2]]
?nnf_binary_cross_entropy
?nnf_cross_entropy
out
nnf_cross_entropy(out,b[[2]])
source("G:/マイドライブ/MyDocument/研究室/内城/paper/VSMD/torchtest.R")
source("G:/マイドライブ/MyDocument/研究室/内城/paper/VSMD/torchtest.R")
source("G:/マイドライブ/MyDocument/研究室/内城/paper/VSMD/torchtest.R")
plot(losses)
source("G:/マイドライブ/MyDocument/研究室/内城/paper/VSMD/torchtest.R")
plot(losses)
x<-1:20
y<-rep(0,20)
y[1]<-1
y[2]<-1/2
y[3]<-3/10
plot(x,y)
library(ggplot2)
dat<-data.frame(x=x,y=y)
ggplot2(dat,aes(x=x,y=y))+geom_segment()
ggplot(dat,aes(x=x,y=y))+geom_segment()
ggplot(dat,aes(x=x,y=y))+geom_segment(aes(xend=x,yend=0))
ggplot(dat,aes(x=x,y=y))+geom_segment(aes(xend=x,yend=0))+geom_point()
library(tuneR)
x<-readWave("F:/backup/音響学入門/CDROM-contents/contents/sounds/04/a.wav")
plot(x)
x0<-extractWave(x,from=0.1,to=0.15,xunit="time")
plot(x0)
y<-fft(x0@left)
length(y)
plot(abs(y),xlim=c(1,1000),log="y")
plot(abs(y),xlim=c(1,1000),log="y",type="l")
plot(seq(0,16000,length.out=1000),abs(y),xlim=c(1,1000),log="y",type="l",xlab="Magnitude",ylab="Frequency (Hz)")
plot(seq(0,16000,length.out=length(y)),abs(y),xlim=c(1,1000),log="y",type="l",xlab="Magnitude",ylab="Frequency (Hz)")
plot(seq(0,16000,length.out=length(y)),abs(y),xlim=c(1,8000),log="y",type="l",xlab="Magnitude",ylab="Frequency (Hz)")
plot(seq(0,16000,length.out=length(y)),abs(y),xlim=c(1,8000),log="y",type="l",ylab="Magnitude",xlab="Frequency (Hz)")
x<-c(1,0,3,2,-1,2,2,1,2,-1)
x
mean(x)
t.test(x)
x<-c(1,0,3,2,-2,2,2,1,2,-1)
t.test(x)
table(x)
x<-c(1,0,3,2,-2,2,2,1,2,-1)
??whittney
wilcox.test(x)
x<-c(1,0,3,2,-2,2,2,1,2,1)
wilcox.test(x)
t.test(x)
?t.test
?bonferroni
??bonferroni
?t.test
foo <- function(x) UseMethod("foo")
foo
foo.default <- function(x) {cat("x=",x,"\n")}
foo(1)
foo("abc")
class("abc")
foo.character <- function(x){cat("x='",x,"'\n")}
foo("abc")
predict
setwd("~/Downloads/simpleTorch")
library(devtools)
??package
install()
remove.packages("cli")
install.packages("cli")
install.packages("cli")
library(simpleTorch)
data(iris)
train_ind <- sample.int(nrow(iris),floor(nrow(iris)*0.8))
train_data <- iris[train_ind,]
val_data <- iris[-train_ind,]
dls <- prepare_dataloader(train_x=train_data[,-5],
train_y=as.integer(train_data[,5]),
xtype=torch_float32(), ytype=torch_long(),
val_x=val_data[,-5],
val_y=as.integer(val_data[,5]))
library(torch)
dls <- prepare_dataloader(train_x=train_data[,-5],
train_y=as.integer(train_data[,5]),
xtype=torch_float32(), ytype=torch_long(),
val_x=val_data[,-5],
val_y=as.integer(val_data[,5]))
res <- train(dl=dls$dataloader$train,
val_dl=dls$dataloader$validate,
topology=list(
list("linear",4,10),
list("relu"),
list("linear",10,3)
),
optim="adam",
loss="crossentropy",
nepoch=30,
lr=0.01
)
class(res)
class(res[[1]])
torch_save(res[[1]],"test.torch")
source("~/Downloads/simpleTorch/R/simpletorch.R")
source("~/.active-rstudio-document")
out <- predict(res$model,train_data)
out <- predict(res$model,train_data[,1:4])
out
apply(out,1,which.max)
apply(out,1,which.max)==as.integer(train_data[,5])
res$model
